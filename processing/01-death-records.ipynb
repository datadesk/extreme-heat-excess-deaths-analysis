{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546f4c2e-0327-4bef-aa44-f9eb72bfcde5",
   "metadata": {},
   "source": [
    "# Death records\n",
    "\n",
    "This notebook parses and cleans up the raw deaths records data from the California Department of Public Health."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12772a57-e6bd-4251-8f75-c7fd73d3e958",
   "metadata": {},
   "source": [
    "Import Python tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "118d2fbb-75be-484e-a8ed-4f268a705ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776430a3-09fd-4e55-8d4b-f59ca332449c",
   "metadata": {},
   "source": [
    "Functions to read in and standardize different file types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e6f1be9-2f41-4d79-afe8-f609fdd1c90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dat(\n",
    "    name,\n",
    "    year,\n",
    "    sep=\",\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"last_name\",\n",
    "        \"first_name\",\n",
    "        \"middle_name\",\n",
    "        \"sex\",\n",
    "        \"date_of_birth\",\n",
    "        \"date_of_death\",\n",
    "        \"place_of_birth_state_or_foreign_country\",\n",
    "        \"place_of_death_county\",\n",
    "        \"fathers_last_name\"\n",
    "    ],\n",
    "    parse_dates=[\"date_of_death\"],\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads the provided DAT file into a DataFrame.\n",
    "    \"\"\"\n",
    "    # Read in the CSV file\n",
    "    path = f\"../input/raw/death-records/{name}\"\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        sep=sep,\n",
    "        header=header,\n",
    "        names=names,\n",
    "        parse_dates=parse_dates,\n",
    "        **kwargs\n",
    "    )\n",
    "    print(f\"- {len(df)} total records\")\n",
    "    # Set metadata columns\n",
    "    df['date_of_birth'] = pd.to_datetime(df.date_of_birth, errors='coerce')\n",
    "    df['file_name'] = name\n",
    "    df['file_year'] = year\n",
    "    # Trim invalid dates\n",
    "    trimmed_df = trim_invalid_dates(df)\n",
    "    print(f\"- {len(df) - len(trimmed_df)} out of year records trimmed\")\n",
    "    # Pass it back\n",
    "    return trimmed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f47ed378-1c89-4705-a4a5-238ff2d83c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xlsx(name, year):\n",
    "    \"\"\"\n",
    "    Reads in the provided Excel file and returns a DataFrame.\n",
    "    \"\"\"\n",
    "    # Read in Excel file\n",
    "    path = f\"../input/raw/death-records/{name}\"\n",
    "    df = pd.read_excel(path)\n",
    "    print(f\"- {len(df)} total records\")\n",
    "    # Standardize column names\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.rename(columns={\"father's_last_name\": \"fathers_last_name\"}, inplace=True)\n",
    "    # Set metadata columns\n",
    "    df['date_of_birth'] = pd.to_datetime(df.date_of_birth, errors='coerce')\n",
    "    df['date_of_death'] = pd.to_datetime(df.date_of_death, errors='coerce')\n",
    "    df['file_name'] = name\n",
    "    df['file_year'] = year\n",
    "    # Trim invalid dates\n",
    "    trimmed_df = trim_invalid_dates(df)\n",
    "    print(f\"- {len(df) - len(trimmed_df)} out of year records trimmed\")\n",
    "    # Pass it back\n",
    "    return trimmed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19eeb853-c8b8-4aa2-bcef-76a857f42cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_invalid_dates(df):\n",
    "    \"\"\"\n",
    "    Removes records for which there are invalid DOB or DODs\n",
    "    \"\"\"\n",
    "    # Filter out rows without a date of death\n",
    "    filter_na_dod_df = df[~df.date_of_death.isnull()]\n",
    "    # Filter out rows without a date of birth\n",
    "    filter_na_dob_df = filter_na_dod_df[~filter_na_dod_df.date_of_birth.isnull()]\n",
    "    return filter_na_dob_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840b9ffb-69fd-4039-b171-f6bf4152a2cf",
   "metadata": {},
   "source": [
    "Crosswalk with all of our source data files and key input options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79ec7e0e-7cf4-4748-8d54-5c9f743ad3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [\n",
    "    dict(name=\"2010.DAT\", year=2010),\n",
    "    dict(name=\"2011.DAT\", year=2011),\n",
    "    dict(name=\"2012.DAT\", year=2012),\n",
    "    dict(name=\"2013.DAT\", year=2013),\n",
    "    dict(name=\"PUBLIC_DEATH_010114-123114.xlsx\", year=2014),\n",
    "    dict(name=\"Public_DEATH_010115-123115FINAL.xlsx\", year=2015),\n",
    "    dict(name=\"PUBLIC_DEATH_010116-123116.xlsx\", year=2016),\n",
    "    dict(name=\"PUBLIC_DEATH_010117-123117.xlsx\", year=2017),\n",
    "    dict(name=\"PUBLIC_DEATH_2018.xlsx\", year=2018),\n",
    "    dict(name=\"PUBLIC_DEATH_2019.xlsx\", year=2019)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f540a393-4f8c-4a7f-92b0-22409718c136",
   "metadata": {},
   "source": [
    "Loop through the data files and read them in one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39c482f8-4366-4e99-a453-7e9d8e1c6bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening 2010.DAT\n",
      "- 264108 total records\n",
      "- 19 out of year records trimmed\n",
      "Opening 2011.DAT\n",
      "- 269949 total records\n",
      "- 22 out of year records trimmed\n",
      "Opening 2012.DAT\n",
      "- 272016 total records\n",
      "- 0 out of year records trimmed\n",
      "Opening 2013.DAT\n",
      "- 278489 total records\n",
      "- 0 out of year records trimmed\n",
      "Opening PUBLIC_DEATH_010114-123114.xlsx\n",
      "- 238862 total records\n",
      "- 44 out of year records trimmed\n",
      "Opening Public_DEATH_010115-123115FINAL.xlsx\n",
      "- 259361 total records\n",
      "- 57 out of year records trimmed\n",
      "Opening PUBLIC_DEATH_010116-123116.xlsx\n",
      "- 263225 total records\n",
      "- 62 out of year records trimmed\n",
      "Opening PUBLIC_DEATH_010117-123117.xlsx\n",
      "- 269409 total records\n",
      "- 69 out of year records trimmed\n",
      "Opening PUBLIC_DEATH_2018.xlsx\n",
      "- 269977 total records\n",
      "- 65 out of year records trimmed\n",
      "Opening PUBLIC_DEATH_2019.xlsx\n",
      "- 270783 total records\n",
      "- 71 out of year records trimmed\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for d in file_list:\n",
    "    print(f\"Opening {d['name']}\")\n",
    "    if d['name'].lower().endswith(\".dat\"):\n",
    "        df = read_dat(d['name'], d['year'])\n",
    "    else:\n",
    "        df = read_xlsx(d['name'], d['year'])\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3ca81f-3752-46bf-892f-c90e5bcf2a98",
   "metadata": {},
   "source": [
    "Combine dataframes into master file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "724bd289-5cbe-4d40-be21-2ab2f10d695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15667582-5b30-458f-8c15-0d9019ecd649",
   "metadata": {},
   "source": [
    "Filter out years not in study period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "426008af-96de-43d3-9e77-c342bdcd325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df = concat_df[(concat_df.date_of_death > \"2010-01-01\") & (concat_df.date_of_death < \"2019-12-31\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f2f59a-71cd-461e-bd38-4eef925c036b",
   "metadata": {},
   "source": [
    "Remove duplicate deaths using common set of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a1af59d-a18f-4f12-9030-f15e6598e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_df = filter_df.drop_duplicates(\n",
    "    subset=['last_name', 'first_name', 'sex', 'date_of_birth', 'date_of_death', 'place_of_death_county'],\n",
    "    keep='last'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3151f92e-bf60-4c86-8762-d9c0bc00f052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 107362 duplicated records\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dropped {len(filter_df) - len(deduped_df)} duplicated records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d910e15-cde9-4cc8-ae92-191f2b4302d6",
   "metadata": {},
   "source": [
    "Write it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3f17622-4162-4f53-afe1-6a0442a7cdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_df.to_csv(\n",
    "    \"../input/processed/death-records.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "062f5f43-f71f-4d98-95a6-2d4bfb2ed99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 2546720 records to file\n"
     ]
    }
   ],
   "source": [
    "print(f\"Wrote {len(deduped_df)} records to file\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
